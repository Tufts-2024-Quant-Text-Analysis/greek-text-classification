{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Comparison: t-test & Cohen's d\n",
    "Brezina ch 6, p 186-197\n",
    "\n",
    "## t-test\n",
    "The t-test is used for comparing two groups. It considers both the differences between the groups themselves, as well as the internal *variation* of the groups. In order to understand the t-test, however, we need to understand variance. **Variance** as a statistical measure captures the spread between numbers in a dataset:\n",
    "$$\n",
    "\\text{Variance} = \\frac{\\text{sum of squared distances from the mean}}{\\text{degrees of freedom}}\n",
    "$$\n",
    "  \n",
    "&nbsp;    \n",
    "&nbsp;      \n",
    "In mathematical notation, variance is:\n",
    "$$\n",
    "S^2 = \\frac{\\sum{(x_i - \\bar{x})^2}}{n-1} \n",
    "$$\n",
    "$S^2$ = sample variance  \n",
    "$x_i$ = the value of one observation  \n",
    "$\\bar{x}$ = the mean value of all observations  \n",
    "$n$ = the number of observations  \n",
    "\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "The **t-test** formula is as follows:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\text{Mean of group 1} - \\text{Mean of group 2}}{\\sqrt{\\frac{\\text{Variance of group 1}}{\\text{Number of cases in group 1}} + \\frac{\\text{Variance of group 2}}{\\text{Number of cases in group 2}}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy\n",
    "%pip install pingouin\n",
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11734474667019203, 0.11428004422646217, 0.133139227104288, 0.12105616469008727, 0.12001605565962002, 0.12146957520091849, 0.12077660110943016, 0.11168054665812513, 0.12669683257918551]\n",
      "[0.10786882642528188, 0.10967354982435096, 0.11988911988911989, 0.11278803395768765, 0.1081267217630854, 0.10293621329733378, 0.11324570273003033, 0.11416241663397411, 0.1161764705882353]\n",
      "T-statistic: 3.339001894964257, P-value: 0.004162703662638815\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "files = [\n",
    "    \"./data/poetry/tlg0012.tlg001.perseus-grc1.tb.xml\", #iliad\n",
    "    \"./data/poetry/tlg0012.tlg002.perseus-grc1.tb.xml\" #odyssey\n",
    "]\n",
    "\n",
    "def get_rel_freqs_per_book(f, pos, num_books=24):\n",
    "    tree = etree.parse(f)\n",
    "    pos_vals=[0 for i in range(num_books)]\n",
    "    total_vals=[0 for i in range(num_books)]\n",
    "    rel_vals=[0 for i in range(num_books)]\n",
    "\n",
    "    for l in tree.iterfind(\".//sentence\"):\n",
    "        for element in l.findall(\".//word\"):\n",
    "            if l.get(\"subdoc\"):\n",
    "                book_num = int(l.get(\"subdoc\")[0])\n",
    "                if element.get(\"postag\", \" \")[0] == pos:\n",
    "                    pos_vals[book_num] += 1 \n",
    "                    total_vals[book_num] += 1\n",
    "                elif element.get(\"postag\", \" \")[0]:\n",
    "                    total_vals[book_num] += 1\n",
    "\n",
    "    for i in range(num_books):\n",
    "        try:\n",
    "            rel_vals[i] = pos_vals[i]/total_vals[i]\n",
    "        except:\n",
    "            rel_vals[i] = 0\n",
    "\n",
    "    return rel_vals\n",
    "\n",
    "def count_pos(words, pos: str):\n",
    "    return len([w for w in words if w.get(\"postag\", \" \")[0] == pos])\n",
    "\n",
    "iliad_freq = get_rel_freqs_per_book(files[0], \"a\")\n",
    "odyssey_freq = get_rel_freqs_per_book(files[1], \"a\")\n",
    "\n",
    "iliad_freq = iliad_freq[1:10]\n",
    "odyssey_freq = odyssey_freq[1:10]\n",
    "\n",
    "print(iliad_freq)\n",
    "print(odyssey_freq)\n",
    "\n",
    "t_stat, p_value = ttest_ind(iliad_freq, odyssey_freq)\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohen's *d*\n",
    "> \"In addition to the statistical test, we also need to calculate an effect size measure to evaluate in standardized terms (i.e. units comparable across linguistic variables and corpora) the size of the difference between the two groups.\" [@Brezina2018]  \n",
    "\n",
    "You might recall we've already talked about Cohen's d when we discussed correlation measures. It's the same metric, here we're just applying it in a different context. Brezina describes Cohen's d as \"the difference between the two means expressed in standard deviation units\"\n",
    "\n",
    "$$\n",
    "\\text{Cohen's } d = \\frac{\\text{Mean of group1 - Mean of group2}}{\\text{pooled }SD}\n",
    "$$\n",
    "\n",
    "Interpretation of *d*: *d* > 0.3 small, *d* > 0.5 medium, *d* > 0.8 large effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d: 1.5740205882159723\n",
      "[0.43 2.72]\n"
     ]
    }
   ],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "cohens_d = pg.compute_effsize(\n",
    "    iliad_freq, \n",
    "    odyssey_freq, \n",
    "    eftype='cohen'\n",
    ")\n",
    "\n",
    "print(f\"Cohen's d: {cohens_d}\")\n",
    "\n",
    "result = pg.compute_esci(\n",
    "    cohens_d,\n",
    "    len(iliad_freq),\n",
    "    len(odyssey_freq),\n",
    "    paired=False, \n",
    "    eftype='cohen',\n",
    "    confidence=0.95  # 95% confidence interval\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "Text classification is a process in Machine Learning that categorizes text into a certain category. We've seen a version of text classification before, when we looked at Greek dramas in Week 6 and used TF-IDF data to assign text to a dramatist. Sentiment Analysis, which was part of our journal club, is also a form of text classification.\n",
    "\n",
    "This week, we will use BERT to attempt to classify text as prose or poetry.\n",
    "\n",
    "## Corpus Selection\n",
    "\n",
    "We're going to use the [Perseus Treebank](https://perseusdl.github.io/treebank_data/) data as our initial corpus. \n",
    "\n",
    "> Discuss: What can you observe about our corpus? What are the potential issues or advantages with using this corpus?\n",
    "\n",
    "The data has already been preproccessed using treebank_preprocess.py. This is similar to some of the preprocessing we've seen in the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df_all = pd.read_pickle(\"./corpus.pickle\")\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install torch\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Now that we've preprocessed the text, we should do some exploration to form descriptive statistics. \n",
    "1. Considering your initial observations about the corpus, explore the corpus both quantitatively and qualitatively.\n",
    "2. Use data visualization to demonstrate what you've found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n",
    "For this exercise, we're using [this](https://huggingface.co/bowphs/GreBerta) BERT model, pretrained on Ancient Greek. BERT stands for Bidirectional Encoder Representations from Transformers. \"Bidirectional\" meaning that it processes text from left to right and from right to left. This is useful for English, and particularly useful for ancient Greek, where word order is more flexible. \"Encoder Representations from Transformers\" means that it takes the same input processing as transformer models. \n",
    "\n",
    "### Training Bert \n",
    "You can view the code for training BERT at bert.py.  \n",
    "In class, we are going to do our processing in Google Colab so that we can leverage the extra computational resources. \n",
    "If you're running the code on your own, you can copy paste bert.py into Colab. Be sure to Runtime -> Change Runtime Type -> GPU. Also do not forget to bring your pickled data into Colab.\n",
    "\n",
    "Since training takes a while, we've provided a pre-trained model for you already. Unfortunately, the file is too large for GitHub, but you can access it [here](https://tufts.box.com/s/k44jjmvklnfkm5g30dbkpqvn9wxuxth9). Once downloaded, you can try it out with whatever text you want using the below code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import os\n",
    "\n",
    "def predict_text(texts, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encodings = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = model(**encodings)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        return predictions.cpu().numpy()\n",
    "\n",
    "device = torch.device('cuda') #CHANGE THIS LINE from 'cuda' to 'cpu' if you are not running on a gpu!\n",
    "\n",
    "# load model and tokenizer\n",
    "model_name = \"bowphs/GreBerta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2\n",
    ") .to(device)\n",
    "\n",
    "# load saved model if available\n",
    "model_path = 'best_model.pt' #you may need to change the path depending on what folder you have best_model.pt in\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading saved model from {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    #your Greek text goes here!\n",
    "    new_texts = [\"ποικιλόθρον᾿ ἀθανάτ᾿ Αφρόδιτα, παῖ Δίος δολόπλοκε, λίσσομαί σε,μή μ᾿ ἄσαισι μηδ᾿ ὀνίαισι δάμνα, πότνια, θῦμον,\"]\n",
    "\n",
    "    predictions = predict_text(new_texts, model, tokenizer, device)\n",
    "\n",
    "    for text, pred in zip(new_texts, predictions):\n",
    "        prose_prob, poetry_prob = pred\n",
    "        predicted_class = \"Poetry\" if poetry_prob > 0.5 else \"Prose\"\n",
    "        print(f\"Text: {text[:50]}...\")\n",
    "        print(f\"Prediction: {predicted_class}\")\n",
    "        print(f\"Poetry probability: {poetry_prob:.2%}\")\n",
    "        print(f\"Prose probability: {prose_prob:.2%}\\n\")\n",
    "else:\n",
    "    print(\"No saved model found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Using the resources provided in latin-text-classification, train a Latin BERT model to identify poetry vs prose. \n",
    "2. Using either Latin or Greek, test the BERT model using prose and/or poetry that the model was NOT trained on. If you know ancient Greek or Latin, choose language that you think might stump the model. What do the results tell you about the effectiveness of our classification model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
